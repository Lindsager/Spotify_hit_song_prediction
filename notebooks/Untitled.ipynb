{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eff09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and save logistic_regression model\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.60      0.69      3229\n",
      "           1       0.68      0.85      0.76      3268\n",
      "\n",
      "    accuracy                           0.73      6497\n",
      "   macro avg       0.74      0.73      0.72      6497\n",
      "weighted avg       0.74      0.73      0.72      6497\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1946 1283]\n",
      " [ 488 2780]]\n",
      "Train and save random_forest model\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75      3229\n",
      "           1       0.74      0.85      0.79      3268\n",
      "\n",
      "    accuracy                           0.77      6497\n",
      "   macro avg       0.78      0.77      0.77      6497\n",
      "weighted avg       0.78      0.77      0.77      6497\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2226 1003]\n",
      " [ 481 2787]]\n",
      "Train and save knn model\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.63      0.69      3229\n",
      "           1       0.69      0.82      0.75      3268\n",
      "\n",
      "    accuracy                           0.73      6497\n",
      "   macro avg       0.73      0.72      0.72      6497\n",
      "weighted avg       0.73      0.73      0.72      6497\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2019 1210]\n",
      " [ 575 2693]]\n",
      "Train and save xgboost model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linds\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.75      3229\n",
      "           1       0.74      0.85      0.79      3268\n",
      "\n",
      "    accuracy                           0.77      6497\n",
      "   macro avg       0.78      0.77      0.77      6497\n",
      "weighted avg       0.78      0.77      0.77      6497\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2250  979]\n",
      " [ 504 2764]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib  # for saving models\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Read in the cleaned dataset and drop non-numeric features\n",
    "def read_cleaned_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data_numeric = data.drop(['song', 'artist', 'song_artist'], axis=1)\n",
    "    return data_numeric\n",
    "\n",
    "# Prepare features and target variable\n",
    "def prepare_data_for_modeling(data_numeric, target_column):\n",
    "    X = data_numeric.drop(target_column, axis=1)\n",
    "    y = data_numeric[target_column]\n",
    "    column_names = X.columns.tolist()\n",
    "    return X, y, column_names\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Feature scaling\n",
    "def scale_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Function to save test data with column names\n",
    "def save_test_data(X_test_scaled, y_test, column_names, X_test_filepath, y_test_filepath):\n",
    "    X_test_df = pd.DataFrame(X_test_scaled, columns=column_names)\n",
    "    X_test_df.to_csv(X_test_filepath, index=False)\n",
    "    y_test.to_csv(y_test_filepath, index=False)\n",
    "\n",
    "# Function to save pre-trained models for easier testing \n",
    "def save_model(model, filename):\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "# Model 1 Training - Logistic Regression\n",
    "def train_and_save_logistic_regression(X_train_scaled, y_train, filename='../models/logistic_regression_model.pkl'):\n",
    "    model_lr = LogisticRegression()\n",
    "    model_lr.fit(X_train_scaled, y_train)\n",
    "    save_model(model_lr, filename)\n",
    "    return model_lr\n",
    "\n",
    "# Model 2 Training - Random Forest\n",
    "def train_and_save_random_forest(X_train_scaled, y_train, filename='../models/random_forest_model.pkl'):\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_rf.fit(X_train_scaled, y_train)\n",
    "    save_model(model_rf, filename)\n",
    "    return model_rf\n",
    "\n",
    "# Model 3 Training - k-Nearest Neighbor\n",
    "def train_and_save_knn(X_train_scaled, y_train, filename='../models/knn_model.pkl'):\n",
    "    model_knn = KNeighborsClassifier()\n",
    "    model_knn.fit(X_train_scaled, y_train)\n",
    "    save_model(model_knn, filename)\n",
    "    return model_knn\n",
    "\n",
    "# Model 4 Training - XGBoost\n",
    "def train_and_save_xgboost(X_train_scaled, y_train, filename='../models/xgboost_model.pkl'):\n",
    "    model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model_xgb.fit(X_train_scaled, y_train)\n",
    "    save_model(model_xgb, filename)\n",
    "    return model_xgb\n",
    "\n",
    "# Function for model evaluation\n",
    "def evaluate_model(model, X_test_scaled, y_test):\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    # Note: precision_recall_curve returns 3 arrays: precision, recall, thresholds. They need to be handled if used.\n",
    "    precision, recall, _ = precision_recall_curve(y_test, model.predict_proba(X_test_scaled)[:,1])\n",
    "    # Implement logic to use or display precision-recall data as needed\n",
    "    # For example, you might plot the precision-recall curve here\n",
    "    \n",
    "# Main pipeline execution\n",
    "def main():\n",
    "    # Assuming `data_filepath` and `target_column` are defined and the dataset is clean\n",
    "    data_numeric = read_cleaned_data('../data/final/modeling_dataset_32k.csv')\n",
    "    X, y, column_names = prepare_data_for_modeling(data_numeric, 'hit_song')\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    X_train_scaled, X_test_scaled = scale_features(X_train, X_test)\n",
    "    save_test_data(X_test_scaled, y_test, column_names,'../data/final/X_test_scaled.csv','../data/final/y_test.csv')\n",
    "\n",
    "    # Train and save each model\n",
    "    models = {\n",
    "        'logistic_regression': train_and_save_logistic_regression,\n",
    "        'random_forest': train_and_save_random_forest,\n",
    "        'knn': train_and_save_knn,\n",
    "        'xgboost': train_and_save_xgboost\n",
    "    }\n",
    "\n",
    "    for name, train_func in models.items():\n",
    "        print(f\"Train and save {name} model\")\n",
    "        model = train_func(X_train_scaled, y_train)\n",
    "        evaluate_model(model, X_test_scaled, y_test)\n",
    "        # Optionally, add a line here to plot or further analyze model performance\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc313bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
